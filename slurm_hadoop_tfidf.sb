#!/usr/bin/env bash

# run this slurm script by executing:
# sbatch /shared/patents/nltk-hadoop/slurm_hadoop_tfidf.sb
# (or whatever the absolute path is)

# sesarch for this to find it in `sinfo`
#SBATCH --job-name=mapreduce_tfidf_patent_claims

# request the hdfs name node and yarn manager
#SBATCH --nodelist=n05.sampa

# need to get linuxbrew and associated env vars:
source /shared/patents/settings.sh

HDFS_CLAIMS_PATH=hdfs:/shared/patents/claims_splits
OUTPUT=hdfs:/shared/patents/similarities

# still need to pass customm stop words list here as well
srun ./mapred_tfidf.py -i $HDFS_CLAIMS_PATH -o $OUTPUT
